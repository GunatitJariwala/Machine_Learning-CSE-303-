{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: Imports and Setup ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Changed from TfidfVectorizer based on later screenshots\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 2: Load Data ---\n",
    "# Make sure 'resume.csv' is in your directory\n",
    "resume_df = pd.read_csv('resume.csv', encoding='latin-1')\n",
    "print(\"Initial Data Head:\")\n",
    "print(resume_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ed778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: Initial Exploration and Conversion ---\n",
    "print(\"\\nNull Values:\")\n",
    "print(resume_df.isnull().sum())\n",
    "print(\"\\nClass Value Counts Before Conversion:\")\n",
    "print(resume_df['class'].value_counts()) # Shows 'not_flagged' and 'flagged'\n",
    "\n",
    "# Convert 'class' column to numerical (0 and 1)\n",
    "resume_df['class'] = resume_df['class'].apply(lambda x: 1 if x == 'flagged' else 0)\n",
    "print(\"\\nClass Value Counts After Conversion:\")\n",
    "print(resume_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: Stopwords Preparation ---\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words('english')\n",
    "# Extend stopwords with common non-content words found in text data\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'email', 'com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b86c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: Define Preprocessing Function ---\n",
    "def preprocess(text):\n",
    "    # Remove stop words and remove words with 2 or less characters\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        # Check against both gensim default STOPWORDS and the extended custom list\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
    "            result.append(token)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 6: Apply Preprocessing ---\n",
    "resume_df['cleaned'] = resume_df['resume_text'].apply(preprocess)\n",
    "\n",
    "# Display a sample of the cleaned text\n",
    "print(\"Cleaned Text (Sample 0):\\n\", resume_df['cleaned'][0])\n",
    "print(\"\\nOriginal Text (Sample 0):\\n\", resume_df['resume_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efe41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 7: Word Cloud for Class 0 (Not Flagged) ---\n",
    "plt.figure(figsize=(10, 10))\n",
    "subset = resume_df[resume_df['class'] == 0]\n",
    "text = subset.cleaned.values\n",
    "\n",
    "cloud_0 = WordCloud(\n",
    "    stopwords=stop_words,\n",
    "    background_color='black',\n",
    "    collocations=False,\n",
    "    max_words=2000, \n",
    "    width=1600, \n",
    "    height=800\n",
    ").generate(\" \".join(text))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud for Not Flagged Resumes', fontsize=20)\n",
    "plt.imshow(cloud_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 8: Word Cloud for Class 1 (Flagged) ---\n",
    "plt.figure(figsize=(10, 10))\n",
    "subset = resume_df[resume_df['class'] == 1]\n",
    "text = subset.cleaned.values\n",
    "\n",
    "cloud_1 = WordCloud(\n",
    "    stopwords=stop_words,\n",
    "    background_color='black',\n",
    "    collocations=False,\n",
    "    max_words=2000, \n",
    "    width=1600, \n",
    "    height=800\n",
    ").generate(\" \".join(text))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud for Flagged Resumes', fontsize=20)\n",
    "plt.imshow(cloud_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12815e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 9: Vectorization (Count Vectorizer) ---\n",
    "# CountVectorizer is used here, as indicated by the later screenshots.\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(resume_df['cleaned'])\n",
    "y = resume_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 10: Train-Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing Samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 12: Prediction and Evaluation ---\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(\"--- Classification Report (Naive Bayes) ---\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Not Flagged (0)', 'Flagged (1)'],\n",
    "            yticklabels=['Not Flagged (0)', 'Flagged (1)'])\n",
    "plt.title('Confusion Matrix for Naive Bayes')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21945cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fbcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d7a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e98500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
